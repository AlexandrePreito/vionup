import { NextRequest, NextResponse } from 'next/server';
import { supabaseAdmin } from '@/lib/supabase';

const SUPABASE_URL = process.env.NEXT_PUBLIC_SUPABASE_URL!;
const SUPABASE_SERVICE_KEY = process.env.SUPABASE_SERVICE_ROLE_KEY!;

// Cache global de tokens do Power BI
const tokenCache = new Map<string, { token: string; expires: number }>();

async function getPowerBIToken(connection: any): Promise<string> {
  const cacheKey = connection.client_id;
  const cached = tokenCache.get(cacheKey);
  
  // Se tem cache v√°lido, usar
  if (cached && cached.expires > Date.now()) {
    console.log('‚úÖ Usando token em cache');
    return cached.token;
  }
  
  // Buscar novo token
  console.log('üîë Buscando novo token do Power BI...');
  const tokenResponse = await fetch(
    `https://login.microsoftonline.com/${connection.tenant_id}/oauth2/v2.0/token`,
    {
      method: 'POST',
      headers: { 'Content-Type': 'application/x-www-form-urlencoded' },
      body: new URLSearchParams({
        client_id: connection.client_id,
        client_secret: connection.client_secret,
        scope: 'https://analysis.windows.net/powerbi/api/.default',
        grant_type: 'client_credentials',
      }),
    }
  );

  if (!tokenResponse.ok) {
    const errorText = await tokenResponse.text();
    throw new Error(`Erro ao obter token do Power BI: ${errorText}`);
  }

  const { access_token, expires_in } = await tokenResponse.json();
  
  if (!access_token) {
    throw new Error('Token n√£o retornado na resposta do Power BI');
  }
  
  // Cachear por 50 minutos (expires_in geralmente √© 3600s = 1h)
  tokenCache.set(cacheKey, {
    token: access_token,
    expires: Date.now() + ((expires_in || 3600) - 600) * 1000 // 10min de margem
  });
  
  console.log('‚úÖ Novo token obtido e cacheado');
  return access_token;
}

// ============================================================
// INTERFACES E TIPOS
// ============================================================

interface DaxQueryOptions {
  workspaceId: string;
  datasetId: string;
  accessToken: string;
  query: string;
  timeoutMs?: number;
  retryableColumns?: { column: string; entityType: string }[];
}

interface DaxQueryResult {
  rows: any[];
  retried?: boolean;
  retriedColumn?: string;
}

// ============================================================
// EXECU√á√ÉO DE QUERY DAX
// ============================================================

async function executeDaxQuery(options: DaxQueryOptions): Promise<DaxQueryResult> {
  const {
    workspaceId,
    datasetId,
    accessToken,
    query,
    timeoutMs = 300000,
    retryableColumns = []
  } = options;

  const url = `https://api.powerbi.com/v1.0/myorg/groups/${workspaceId}/datasets/${datasetId}/executeQueries`;
  const headers = {
    'Content-Type': 'application/json',
    Authorization: `Bearer ${accessToken}`,
  };

  const executeQuery = async (daxQuery: string): Promise<Response> => {
    return Promise.race([
      fetch(url, {
        method: 'POST',
        headers,
        body: JSON.stringify({
          queries: [{ query: daxQuery }],
          serializerSettings: { includeNulls: true },
        }),
      }),
      new Promise<Response>((_, reject) =>
        setTimeout(() => reject(new Error(`Timeout: Query demorou mais de ${timeoutMs / 1000} segundos`)), timeoutMs)
      )
    ]) as Promise<Response>;
  };

  // Primeira tentativa
  let response: Response;
  try {
    response = await executeQuery(query);
  } catch (fetchError: any) {
    throw new Error(`Erro de rede ao executar query DAX: ${fetchError.message}`);
  }

  // Se OK, retornar resultados
  if (response.ok) {
    const result = await response.json();
    return { rows: result?.results?.[0]?.tables?.[0]?.rows || [] };
  }

  // Se erro, verificar se √© retryable
  const errorText = await response.text();

  for (const { column, entityType } of retryableColumns) {
    const isColumnError = errorText.includes(column) &&
      (errorText.includes('cannot be found') ||
       errorText.includes('n√£o pode ser encontrada') ||
       errorText.includes('not be used'));

    if (isColumnError && query.includes(column)) {
      console.log(`üîÑ Retrying sem coluna ${column}...`);

      // Remover coluna da query (gen√©rico)
      const cleanedQuery = query
        .replace(new RegExp(`,\\s*\\w+\\[${column}\\]`, 'gi'), '')
        .replace(new RegExp(`\\w+\\[${column}\\],\\s*`, 'gi'), '');

      try {
        const retryResponse = await executeQuery(cleanedQuery);
        if (retryResponse.ok) {
          const result = await retryResponse.json();
          console.log(`‚úÖ Query executada com sucesso sem ${column}`);
          return {
            rows: result?.results?.[0]?.tables?.[0]?.rows || [],
            retried: true,
            retriedColumn: column
          };
        }
        const retryErrorText = await retryResponse.text();
        throw new Error(`Retry sem ${column} tamb√©m falhou: ${retryErrorText}`);
      } catch (retryError: any) {
        throw new Error(`Erro DAX: ${errorText}. Retry sem ${column}: ${retryError.message}`);
      }
    }
  }

  // N√£o √© retryable ‚Äî propagar erro original
  throw new Error(`Erro ao executar query DAX: ${errorText}`);
}

/**
 * Encontra a posi√ß√£o do ')' que fecha o FILTER externo,
 * usando contagem de par√™nteses para lidar com aninhamento.
 * Retorna a posi√ß√£o do √∫ltimo ')' do FILTER, ou -1 se n√£o encontrou.
 */
function findFilterConditionEnd(query: string): number {
  // Encontrar o '(' de abertura do FILTER
  const filterStart = query.search(/FILTER\s*\(/i);
  if (filterStart === -1) return -1;
  
  // Posi√ß√£o do '(' de abertura
  const openParen = query.indexOf('(', filterStart);
  if (openParen === -1) return -1;
  
  let depth = 1;
  let i = openParen + 1;
  
  while (i < query.length && depth > 0) {
    const char = query[i];
    if (char === '(') depth++;
    else if (char === ')') {
      depth--;
      if (depth === 0) {
        // Encontrou o ')' de fechamento do FILTER
        // O filtro de data deve ser inserido antes deste ')'
        return i;
      }
    }
    i++;
  }
  
  return -1;
}

/**
 * Injeta filtro de data em query DAX de forma segura
 * Usa contagem de par√™nteses para lidar com queries aninhadas
 * @param daxQuery Query DAX original
 * @param dateField Campo de data (ex: 'dt_contabil')
 * @param tableName Nome da tabela (ex: 'CaixaItem')
 * @param startDate Data inicial (formato: YYYY-MM-DD)
 * @param endDate Data final (formato: YYYY-MM-DD)
 * @returns Query DAX com filtro de data injetado
 */
function injectDateFilter(
  daxQuery: string,
  dateField: string,
  tableName: string,
  startDate: string,
  endDate: string
): string {
  // Formatar datas para DATE(YYYY,MM,DD)
  const [startYear, startMonth, startDay] = startDate.split('-').map(Number);
  const [endYear, endMonth, endDay] = endDate.split('-').map(Number);
  
  const dateFilter = `${tableName}[${dateField}] >= DATE(${startYear}, ${startMonth}, ${startDay}) && ${tableName}[${dateField}] <= DATE(${endYear}, ${endMonth}, ${endDay})`;

  // Validar que tableName existe na query, sen√£o tentar extrair
  if (!daxQuery.includes(tableName)) {
    console.warn(`‚ö†Ô∏è Tabela ${tableName} n√£o encontrada na query. Tentando extrair...`);
    const tableMatch = daxQuery.match(/(?:SUMMARIZECOLUMNS|FILTER|SELECTCOLUMNS)\s*\(\s*([^\[]+)\[/i);
    if (tableMatch) {
      const extractedTable = tableMatch[1].trim();
      if (extractedTable !== tableName) {
        // Chamar recursivamente com tabela corrigida
        return injectDateFilter(daxQuery, dateField, extractedTable, startDate, endDate);
      }
    }
  }

  // Normalizar: remover EVALUATE do in√≠cio
  const queryBody = daxQuery.replace(/^EVALUATE\s*/i, '').trim();

  // Caso 1: Query j√° tem FILTER externo ‚Äî adicionar condi√ß√£o com &&
  // Usar contagem de par√™nteses para encontrar o √∫ltimo argumento do FILTER
  const filterMatch = queryBody.match(/^FILTER\s*\(/i);
  if (filterMatch) {
    const insertPos = findFilterConditionEnd(queryBody);
    if (insertPos > 0) {
      // Inserir && dateFilter antes do √∫ltimo )
      const beforeClose = queryBody.substring(0, insertPos).trimEnd();
      const afterClose = queryBody.substring(insertPos);
      return `EVALUATE\n${beforeClose} && (${dateFilter})${afterClose}`;
    }
    // Fallback: envolver tudo
    console.warn('‚ö†Ô∏è N√£o conseguiu encontrar fim do FILTER. Envolvendo em novo FILTER.');
    return `EVALUATE\nFILTER(\n  ${queryBody},\n  ${dateFilter}\n)`;
  }

  // Caso 2/3/4: Query sem FILTER externo ‚Äî envolver com FILTER
  return `EVALUATE\nFILTER(\n  ${queryBody},\n  ${dateFilter}\n)`;
}

interface ProcessResult {
  status: 'processing' | 'completed' | 'empty' | 'day_error';
  queue_id: string;
  day?: string;
  day_records?: number;
  processed_days?: number;
  total_days?: number;
  processed_records?: number;
  has_more?: boolean;
  progress?: number;
  error?: string;
}

// ============================================================
// POST - Processar pr√≥ximo dia da fila
// ============================================================
export async function POST(req: NextRequest): Promise<NextResponse<ProcessResult>> {
  let queueIdForError: string | undefined;
  
  try {
    // Usar supabaseAdmin (sem autentica√ß√£o de usu√°rio)
    const body = await req.json();
    const { queue_id } = body;
    queueIdForError = queue_id;

    // 1. Pegar pr√≥ximo item para processar
    let queueItem: any;

    if (queue_id) {
      // Primeiro, garantir que o status √© 'processing'
      await supabaseAdmin
        .from('sync_queue')
        .update({ status: 'processing', started_at: new Date().toISOString(), updated_at: new Date().toISOString() })
        .eq('id', queue_id)
        .in('status', ['pending', 'processing']); // S√≥ atualiza se pending ou j√° processing

      const { data } = await supabaseAdmin
        .from('sync_queue')
        .select('*')
        .eq('id', queue_id)
        .single();
      queueItem = data;
      
      if (queueItem) {
        console.log(`üìã Queue item: id=${queueItem.id}, status=${queueItem.status}, processed_days=${queueItem.processed_days}/${queueItem.total_days}`);
      }
    } else {
      const { data } = await supabaseAdmin.rpc('get_next_sync_queue_item');
      queueItem = data;
    }

    // Fila vazia ou item n√£o encontrado
    if (!queueItem || !queueItem.id) {
      return NextResponse.json({
        status: 'empty',
        queue_id: '',
        message: 'Nenhum item na fila'
      } as any);
    }

    // Item j√° completado
    // Verificar se item foi cancelado entre itera√ß√µes
    if (queueItem.status === 'cancelled') {
      return NextResponse.json({
        status: 'cancelled',
        queue_id: queueItem.id,
        message: 'Sincroniza√ß√£o cancelada pelo usu√°rio'
      });
    }

    if (queueItem.status === 'completed') {
      return NextResponse.json({
        status: 'completed',
        queue_id: queueItem.id,
        processed_days: queueItem.total_days,
        total_days: queueItem.total_days,
        processed_records: queueItem.processed_records,
        progress: 100,
      });
    }

    // ----------------------------------------------------------
    // 2. Calcular pr√≥ximos DIAS a processar (batch de 1 dia)
    // ----------------------------------------------------------
    const DAYS_PER_BATCH = 1; // ‚úÖ 1 dia por vez (evita timeout)
    const startDate = new Date(queueItem.start_date);
    const endDate = new Date(queueItem.end_date);
    const processedDays = queueItem.processed_days || 0;

    // Calcular range de dias deste batch
    const batchStartDate = new Date(startDate);
    batchStartDate.setDate(batchStartDate.getDate() + processedDays);

    const batchEndDate = new Date(batchStartDate);
    batchEndDate.setDate(batchEndDate.getDate() + DAYS_PER_BATCH - 1);

    // N√£o ultrapassar o endDate
    const endDateOnly = new Date(endDate.getFullYear(), endDate.getMonth(), endDate.getDate());
    const batchEndDateOnly = new Date(batchEndDate.getFullYear(), batchEndDate.getMonth(), batchEndDate.getDate());

    if (batchEndDateOnly > endDateOnly) {
      batchEndDate.setTime(endDate.getTime());
    }

    // Verificar se j√° processou todos
    const batchStartDateOnly = new Date(batchStartDate.getFullYear(), batchStartDate.getMonth(), batchStartDate.getDate());
    if (batchStartDateOnly > endDateOnly) {
      // Finalizar item se j√° passou do √∫ltimo dia
      await supabaseAdmin.rpc('finish_sync_queue_item', {
        p_queue_id: queueItem.id,
        p_status: 'completed',
        p_total_records: queueItem.processed_records || 0,
        p_error_message: null,
      });

      return NextResponse.json({
        status: 'completed',
        queue_id: queueItem.id,
        processed_days: queueItem.total_days,
        total_days: queueItem.total_days,
        processed_records: queueItem.processed_records,
        progress: 100,
      });
    }

    const batchStartDateStr = batchStartDate.toISOString().split('T')[0];
    const batchEndDateStr = batchEndDate.toISOString().split('T')[0];
    const daysInBatch = Math.ceil((batchEndDate.getTime() - batchStartDate.getTime()) / 86400000) + 1;

    console.log(`üìä Processando batch de ${daysInBatch} dias: ${batchStartDateStr} at√© ${batchEndDateStr}`);

    // ----------------------------------------------------------
    // 3. Buscar configura√ß√£o e dados do Power BI
    // ----------------------------------------------------------
    const { data: config, error: configError } = await supabaseAdmin
      .from('powerbi_sync_configs')
      .select('*, connection:powerbi_connections(*)')
      .eq('id', queueItem.config_id)
      .single();

    if (configError) {
      console.error('‚ùå Erro ao buscar configura√ß√£o:', configError);
      await supabaseAdmin.rpc('finish_sync_queue_item', {
        p_queue_id: queueItem.id,
        p_status: 'failed',
        p_total_records: queueItem.processed_records || 0,
        p_error_message: `Erro ao buscar configura√ß√£o: ${configError.message}`,
      });

      return NextResponse.json({
        status: 'day_error',
        queue_id: queueItem.id,
        error: `Erro ao buscar configura√ß√£o: ${configError.message}`,
      }, { status: 500 });
    }

    if (!config) {
      await supabaseAdmin.rpc('finish_sync_queue_item', {
        p_queue_id: queueItem.id,
        p_status: 'failed',
        p_total_records: queueItem.processed_records || 0,
        p_error_message: 'Configura√ß√£o n√£o encontrada',
      });

      return NextResponse.json({
        status: 'day_error',
        queue_id: queueItem.id,
        error: 'Configura√ß√£o n√£o encontrada',
      }, { status: 500 });
    }

    // Validar conex√£o
    if (!config.connection) {
      console.error('‚ùå Conex√£o n√£o encontrada na configura√ß√£o:', config);
      await supabaseAdmin.rpc('finish_sync_queue_item', {
        p_queue_id: queueItem.id,
        p_status: 'failed',
        p_total_records: queueItem.processed_records || 0,
        p_error_message: 'Conex√£o do Power BI n√£o encontrada',
      });

      return NextResponse.json({
        status: 'day_error',
        queue_id: queueItem.id,
        error: 'Conex√£o do Power BI n√£o encontrada',
      }, { status: 500 });
    }

    // Verificar se a entidade tem campo de data
    // Apenas vendas, caixa e fluxo de caixa t√™m campo de data
    const entitiesWithDate = ['sales', 'cash_flow', 'cash_flow_statement'];
    // hasDateField: verifica se a entidade tem campo de data configurado
    // NOTA: N√ÉO depende de is_incremental. Sync FULL tamb√©m precisa processar dia-a-dia
    // para evitar timeout. A diferen√ßa entre full e incremental √© apenas o RANGE de datas.
    const hasDateField = config.date_field && entitiesWithDate.includes(config.entity_type);

    // ----------------------------------------------------------
    // 4. Buscar token do Power BI
    // ----------------------------------------------------------
    if (!config.connection.tenant_id || !config.connection.client_id || !config.connection.client_secret) {
      const missingFields = [];
      if (!config.connection.tenant_id) missingFields.push('tenant_id');
      if (!config.connection.client_id) missingFields.push('client_id');
      if (!config.connection.client_secret) missingFields.push('client_secret');
      
      console.error('‚ùå Campos obrigat√≥rios da conex√£o n√£o encontrados:', missingFields);
      await supabaseAdmin.rpc('finish_sync_queue_item', {
        p_queue_id: queueItem.id,
        p_status: 'failed',
        p_total_records: queueItem.processed_records || 0,
        p_error_message: `Campos obrigat√≥rios da conex√£o n√£o encontrados: ${missingFields.join(', ')}`,
      });

      return NextResponse.json({
        status: 'day_error',
        queue_id: queueItem.id,
        error: `Campos obrigat√≥rios da conex√£o n√£o encontrados: ${missingFields.join(', ')}`,
      }, { status: 500 });
    }

    let access_token: string;
    try {
      access_token = await getPowerBIToken(config.connection);
    } catch (tokenError: any) {
      console.error('‚ùå Erro ao obter token do Power BI:', tokenError.message);
      await supabaseAdmin.rpc('finish_sync_queue_item', {
        p_queue_id: queueItem.id,
        p_status: 'failed',
        p_total_records: queueItem.processed_records || 0,
        p_error_message: `Erro ao obter token do Power BI: ${tokenError.message}`,
      });

      return NextResponse.json({
        status: 'day_error',
        queue_id: queueItem.id,
        error: `Erro ao obter token do Power BI: ${tokenError.message}`,
      }, { status: 500 });
    }

    // ----------------------------------------------------------
    // 5. Construir query DAX com filtro de range de datas
    // ----------------------------------------------------------
    if (!config.dax_query) {
      throw new Error('Query DAX n√£o encontrada na configura√ß√£o');
    }
    const startYear = batchStartDate.getFullYear();
    const startMonth = batchStartDate.getMonth() + 1;
    const startDay = batchStartDate.getDate();

    const endYear = batchEndDate.getFullYear();
    const endMonth = batchEndDate.getMonth() + 1;
    const endDay = batchEndDate.getDate();

    console.log(`üìä Range de datas: ${startYear}-${startMonth}-${startDay} at√© ${endYear}-${endMonth}-${endDay}`);

    // Usar query do config se dispon√≠vel, sen√£o gerar query otimizada para vendas
    let daxQuery: string;
    
    if (config.dax_query && config.dax_query.trim()) {
      // Usar query do config (pode ser para cash_flow, sales, etc.)
      daxQuery = config.dax_query;
      
      // Se tem campo de data, adicionar filtro de range de forma segura
      if (hasDateField && config.date_field) {
        // Extrair nome da tabela da query original
        const tableMatch = daxQuery.match(/SUMMARIZECOLUMNS\s*\(\s*([^\[]+)\[/i) || 
                                        daxQuery.match(/FILTER\s*\(\s*'?([^'\[]+)'?\[/i) ||
                                        daxQuery.match(/SELECTCOLUMNS\s*\(\s*([^\[]+)\[/i);
        const tableName = tableMatch ? tableMatch[1].trim() : '';
        
        if (!tableName) {
          console.warn('‚ö†Ô∏è N√£o foi poss√≠vel extrair nome da tabela da query. Usando campo de data sem prefixo.');
        }
        
        // Formatar datas para YYYY-MM-DD
        const startDateStr = `${startYear}-${String(startMonth).padStart(2, '0')}-${String(startDay).padStart(2, '0')}`;
        const endDateStr = `${endYear}-${String(endMonth).padStart(2, '0')}-${String(endDay).padStart(2, '0')}`;
        
        // Usar tabela extra√≠da ou tentar inferir do campo de data
        const finalTableName = tableName || (config.date_field.includes('[') ? 
          config.date_field.split('[')[0] : 
          'Tabela'); // Fallback gen√©rico
        
        // Injetar filtro de data de forma segura
        daxQuery = injectDateFilter(
          daxQuery,
          config.date_field.replace(/\[|\]/g, ''), // Remove colchetes se houver
          finalTableName,
          startDateStr,
          endDateStr
        );
        
        console.log(`üìÖ Filtro de data injetado: ${finalTableName}[${config.date_field}] de ${startDateStr} at√© ${endDateStr}`);
      }
      
      // Adicionar TOPN apenas se necess√°rio
      // Para entidades com filtro de data: N√ÉO adicionar TOPN (o filtro j√° limita)
      // Para entidades sem data: TOPN(5000) - prote√ß√£o contra timeout
      if (!daxQuery.toUpperCase().includes('TOPN')) {
        // Remover EVALUATE e qualquer espa√ßo/linha ap√≥s, garantindo limpeza
        const queryWithoutEvaluate = daxQuery.replace(/^EVALUATE\s*\n?\s*/i, '').trim();
        // Garantir que n√£o h√° EVALUATE duplicado
        const cleanQuery = queryWithoutEvaluate.replace(/^EVALUATE\s*\n?\s*/i, '').trim();
        
        // N√£o adicionar TOPN quando a query j√° tem FILTER com SUMMARIZECOLUMNS
        // O filtro de data j√° limita os resultados suficientemente
        if (hasDateField) {
          // Com filtro de data, o FILTER j√° limita. TOPN causa materializa√ß√£o desnecess√°ria.
          daxQuery = `EVALUATE\n${cleanQuery}`;
          console.log('üìä Sem TOPN (filtro de data j√° limita resultados)');
        } else {
          daxQuery = `EVALUATE TOPN(5000, ${cleanQuery})`;
          console.log('üìä TOPN(5000) adicionado (sem filtro de data)');
        }
      }
      
      console.log('üìä Usando Query DAX do config:', daxQuery.substring(0, 200));
      if (hasDateField) {
        console.log('üìÖ DAX com filtro:', daxQuery);
      } else {
        console.log(`üìä DAX para entidade sem data (${config.entity_type}):`, daxQuery.substring(0, 200));
      }
    } else {
      // Fallback: Query otimizada para vendas (compatibilidade)
      const tableName = 'VendaItemGeral';
      const dateField = config.date_field || 'dt_contabil';
      const dateFilter = `${tableName}[${dateField}] >= DATE(${startYear}, ${startMonth}, ${startDay}) && ${tableName}[${dateField}] <= DATE(${endYear}, ${endMonth}, ${endDay})`;

      daxQuery = `EVALUATE
TOPN(
  2000,
  FILTER(
    SUMMARIZECOLUMNS(
      ${tableName}[Empresa],
      ${tableName}[idVenda],
      ${tableName}[venda_id],
      ${tableName}[dt_contabil],
      ${tableName}[CodigoMaterial],
      ${tableName}[modo_venda_descr],
      ${tableName}[CodigoFuncionario],
      "cost", [CMV],
      "quantity", [Quantidades],
      "total_value", [Vendas Valor]
    ),
    ${dateFilter}
  )
)`;
      console.log('üìä Usando Query DAX padr√£o (vendas):', daxQuery.substring(0, 200));
    }

    console.log('üîç FULL DAX QUERY:', daxQuery);
    console.log('üìä Query DAX final:', daxQuery);

    // ----------------------------------------------------------
    // 6. Executar query no Power BI
    // ----------------------------------------------------------
    if (!config.connection.workspace_id || !config.dataset_id) {
      const missingFields = [];
      if (!config.connection.workspace_id) missingFields.push('workspace_id');
      if (!config.dataset_id) missingFields.push('dataset_id');

      await supabaseAdmin.rpc('finish_sync_queue_item', {
        p_queue_id: queueItem.id,
        p_status: 'failed',
        p_total_records: queueItem.processed_records || 0,
        p_error_message: `Campos obrigat√≥rios n√£o encontrados: ${missingFields.join(', ')}`,
      });

      return NextResponse.json({
        status: 'day_error',
        queue_id: queueItem.id,
        error: `Campos obrigat√≥rios n√£o encontrados: ${missingFields.join(', ')}`,
      }, { status: 500 });
    }

    let queryResult: DaxQueryResult;
    try {
      queryResult = await executeDaxQuery({
        workspaceId: config.connection.workspace_id,
        datasetId: config.dataset_id,
        accessToken: access_token,
        query: daxQuery,
        retryableColumns: [
          { column: 'Periodo', entityType: 'cash_flow' }
        ]
      });
    } catch (queryError: any) {
      console.error('‚ùå Erro ao executar query DAX:', queryError.message);
      await supabaseAdmin.rpc('finish_sync_queue_item', {
        p_queue_id: queueItem.id,
        p_status: 'failed',
        p_total_records: queueItem.processed_records || 0,
        p_error_message: queryError.message,
      });

      return NextResponse.json({
        status: 'day_error',
        queue_id: queueItem.id,
        error: queryError.message,
      }, { status: 500 });
    }

    const rows = queryResult.rows;
    console.log(`üìä Power BI retornou ${rows.length} registros para o per√≠odo ${batchStartDateStr} a ${batchEndDateStr}`);

    if (rows.length > 5000) {
      console.warn(`‚ö†Ô∏è MUITOS REGISTROS (${rows.length})! Considere reduzir o batch size.`);
    }

    // ----------------------------------------------------------
    // 7. Transformar e salvar dados via Edge Function
    // ----------------------------------------------------------
    if (rows.length > 0) {
      if (!queueItem.company_group_id) {
        console.error('‚ùå company_group_id n√£o encontrado no queueItem:', queueItem);
        await supabaseAdmin.rpc('finish_sync_queue_item', {
          p_queue_id: queueItem.id,
          p_status: 'failed',
          p_total_records: queueItem.processed_records || 0,
          p_error_message: 'company_group_id n√£o encontrado no item da fila',
        });

        return NextResponse.json({
          status: 'day_error',
          queue_id: queueItem.id,
          error: 'company_group_id n√£o encontrado no item da fila',
        }, { status: 500 });
      }

      // Transformar todos os registros
      const transformedRecords = rows.map((row: any) => transformRecord(row, config, queueItem.company_group_id));

      // ============================================================
      // GERAR external_id DETERMIN√çSTICO para registros sem ID
      // ============================================================

      /** Hash determin√≠stico baseado no conte√∫do do registro */
      function deterministicHash(input: string): string {
        let hash = 5381;
        for (let i = 0; i < input.length; i++) {
          hash = ((hash << 5) + hash + input.charCodeAt(i)) & 0x7fffffff;
        }
        return hash.toString(36);
      }

      /** Gera external_id baseado no conte√∫do do registro (sem randomness) */
      function generateExternalId(record: any, entityType: string, row: any): string {
        switch (entityType) {
          case 'cash_flow': {
            // Prioridade 1: idCaixa do Power BI
            const idCaixa = row?.['CaixaItem[Idcaixa]'] || row?.['CaixaItem[idCaixa]'] || 
                            row?.['[Idcaixa]'] || row?.idCaixa || row?.['[idCaixa]'];
            if (idCaixa) return String(idCaixa).trim().toLowerCase();

            // Prioridade 2: hash determin√≠stico dos campos do registro
            const cfKey = JSON.stringify({
              date: record.transaction_date || '',
              employee: record.external_employee_id || '',
              company: record.external_company_id || '',
              amount: record.amount ?? 0,
              type: record.transaction_type || '',
              method: record.payment_method || '',
              mode: record.transaction_mode || ''
            });
            return `cf_${deterministicHash(cfKey)}`;
          }

          case 'cash_flow_statement': {
            const date = record.transaction_date ? String(record.transaction_date).split('T')[0] : '';
            const catId = record.category_id ? String(record.category_id) : '';
            const companyId = record.external_company_id ? String(record.external_company_id) : '';
            if (date && catId) return `${date}|${catId}|${companyId}`.toLowerCase();
            // Fallback determin√≠stico
            const cfsKey = JSON.stringify({ date, catId, companyId, amount: record.amount ?? 0 });
            return `cfs_${deterministicHash(cfsKey)}`;
          }

          default: {
            // Tentar campos comuns de ID
            for (const field of ['codigo', 'id', 'code', 'Codigo', 'Id', 'Code']) {
              const val = record[field] || row?.[field] || row?.[`[${field}]`];
              if (val !== null && val !== undefined && val !== '') {
                return String(val).trim().toLowerCase();
              }
            }
            // Fallback: hash do registro inteiro
            const genericKey = JSON.stringify(row || record);
            return `${entityType}_${deterministicHash(genericKey)}`;
          }
        }
      }

      // Aplicar a todos os registros sem external_id
      transformedRecords.forEach((record: any, index: number) => {
        if (!record.external_id || record.external_id === null || record.external_id === '') {
          record.external_id = generateExternalId(record, config.entity_type, rows[index]);
          if (index < 3 && process.env.NODE_ENV === 'development') {
            console.log(`üîë Generated external_id for ${config.entity_type}:`, record.external_id);
          }
        }
      });

      // ============================================================
      // DEDUPLICATE: Remover duplicados pelo external_id
      // ============================================================
      const uniqueRecords = Array.from(
        new Map(
          transformedRecords.map(record => [record.external_id, record])
        ).values()
      );

      const duplicatesRemoved = transformedRecords.length - uniqueRecords.length;
      if (duplicatesRemoved > 0) {
        console.log(`‚ö†Ô∏è Removidos ${duplicatesRemoved} registros duplicados no batch`);
      }

      console.log(`üíæ Processando ${uniqueRecords.length} registros √∫nicos...`);

      // Use uniqueRecords em vez de transformedRecords daqui em diante
      const transformedRecordsUnique = uniqueRecords;

      // Mapear entity_type para nome da tabela
      const tableMap: Record<string, string> = {
        products: 'external_products',
        employees: 'external_employees',
        companies: 'external_companies',
        sales: 'external_sales',
        cash_flow: 'external_cash_flow',
        cash_flow_statement: 'external_cash_flow_statement',
        categories: 'external_categories',
        stock: 'external_stock'
      };
      
      const tableName = tableMap[config.entity_type];
      
      if (!tableName) {
        throw new Error(`Tipo de entidade n√£o suportado: ${config.entity_type}`);
      }

      // Campos permitidos por entidade ‚Äî DEVE estar em sincronia com entityTypeConfig no page.tsx
      // e com as colunas reais das tabelas external_* no Supabase
      const allowedFields: Record<string, Set<string>> = {
        companies: new Set([
          'external_id', 'name', 'fantasy_name', 'cnpj', 'status',
          'code', 'codigo'
        ]),
        employees: new Set([
          'external_id', 'name', 'external_company_id', 'external_code',
          'email', 'department', 'position', 'status',
          'code', 'codigo'
        ]),
        products: new Set([
          'external_id', 'name', 'external_company_id',
          'type', 'category', 'product_group',
          'code', 'codigo', 'description'
        ]),
        sales: new Set([
          'external_id', 'venda_id', 'external_product_id', 'external_employee_id',
          'external_company_id', 'sale_date', 'sale_mode', 'period',
          'quantity', 'total_value', 'cost'
        ]),
        cash_flow: new Set([
          'external_id', 'external_employee_id', 'external_company_id',
          'transaction_date', 'payment_method', 'transaction_type',
          'transaction_mode', 'period', 'amount'
        ]),
        cash_flow_statement: new Set([
          'external_id', 'category_id', 'external_company_id',
          'transaction_date', 'amount'
        ]),
        categories: new Set([
          'external_id', 'name', 'external_company_id',
          'layer_01', 'layer_02', 'layer_03', 'layer_04',
          'code', 'codigo', 'parent_id'
        ]),
        stock: new Set([
          'external_id', 'external_product_id', 'product_name', 'product_group',
          'external_company_id', 'unit', 'purchase_unit', 'conversion_factor',
          'min_quantity', 'max_quantity', 'quantity',
          'last_cost', 'average_cost', 'updated_at_external'
        ]),
      };

      const allowed = allowedFields[config.entity_type] || new Set();

      // Criar objeto limpo: company_group_id + external_id + raw_data + campos permitidos
      const cleanedRecords = transformedRecordsUnique.map((record: any) => {
        const cleaned: any = {
          company_group_id: record.company_group_id,
          external_id: record.external_id,
          raw_data: record.raw_data,
        };
        for (const field of allowed) {
          if (record[field] !== undefined && record[field] !== null) {
            cleaned[field] = record[field];
          }
        }
        return cleaned;
      });

      // Log resumo apenas em desenvolvimento
      if (process.env.NODE_ENV === 'development' && cleanedRecords.length > 0) {
        console.log(`üì§ Enviando ${cleanedRecords.length} registros para ${config.entity_type}`);
        console.log(`üì§ Exemplo external_id:`, cleanedRecords[0].external_id);
      }

      // ============================================================
      // VALIDAR registros transformados DEPOIS da limpeza
      // ============================================================
      const validationRules: Record<string, { required: string[], types: Record<string, 'string' | 'number' | 'date'> }> = {
        companies: {
          required: ['external_id'],
          types: {}
        },
        employees: {
          required: ['external_id', 'external_company_id'],
          types: {}
        },
        products: {
          required: ['external_id'],
          types: {}
        },
        sales: {
          required: ['external_id', 'external_product_id', 'external_company_id', 'sale_date'],
          types: { quantity: 'number', total_value: 'number', cost: 'number', sale_date: 'date' }
        },
        cash_flow: {
          required: ['external_id', 'transaction_date', 'amount'],
          types: { amount: 'number', transaction_date: 'date' }
        },
        cash_flow_statement: {
          required: ['external_id', 'category_id', 'transaction_date', 'amount'],
          types: { amount: 'number', transaction_date: 'date' }
        },
        categories: {
          required: ['external_id'],
          types: {}
        },
        stock: {
          required: ['external_product_id', 'quantity'],
          types: { quantity: 'number' }
        },
      };

      const rules = validationRules[config.entity_type];
      if (rules) {
        const invalidRecords: any[] = [];
        const validRecords: any[] = [];

        cleanedRecords.forEach((record: any) => {
          // Checar campos obrigat√≥rios
          const missingFields = rules.required.filter(f => {
            const val = record[f];
            return val === undefined || val === null || val === '';
          });

          if (missingFields.length > 0) {
            invalidRecords.push({ record, reason: `Campos faltando: ${missingFields.join(', ')}` });
            return;
          }

          // Checar tipos
          for (const [field, type] of Object.entries(rules.types)) {
            const val = record[field];
            if (val === undefined || val === null) continue; // J√° checado em required

            if (type === 'number' && typeof val !== 'number') {
              const num = parseFloat(val);
              if (isNaN(num)) {
                invalidRecords.push({ record, reason: `${field} n√£o √© n√∫mero: ${val}` });
                return;
              }
              record[field] = num; // Auto-fix
            }
            if (type === 'date' && typeof val === 'string' && !/^\d{4}-\d{2}-\d{2}/.test(val)) {
              invalidRecords.push({ record, reason: `${field} n√£o √© data v√°lida: ${val}` });
              return;
            }
          }

          validRecords.push(record);
        });

        if (invalidRecords.length > 0) {
          console.warn(`‚ö†Ô∏è ${invalidRecords.length}/${cleanedRecords.length} registros inv√°lidos removidos`);
          // Log apenas dos primeiros 3
          invalidRecords.slice(0, 3).forEach(({ record, reason }, i) => {
            console.warn(`  ‚ö†Ô∏è [${i + 1}] ${reason} | external_id: ${record.external_id}`);
          });
        }

        if (validRecords.length === 0) {
          throw new Error(`Nenhum registro v√°lido. Total: ${cleanedRecords.length}, Inv√°lidos: ${invalidRecords.length}. Motivo mais comum: ${invalidRecords[0]?.reason || 'desconhecido'}`);
        }

        // Substituir array com apenas os v√°lidos
        cleanedRecords.splice(0, cleanedRecords.length, ...validRecords);
      }

      // Recovery: tentar recuperar campos obrigat√≥rios do raw_data se n√£o foram mapeados
      cleanedRecords.forEach((record: any) => {
        if (config.entity_type === 'cash_flow' && (record.amount == null || record.amount === 0)) {
          const recovered = recoverNumericFromRawData(record.raw_data, 'amount', ['valor', 'value']);
          if (recovered !== null) record.amount = recovered;
        }
        
        if (config.entity_type === 'sales') {
          if (record.quantity == null || record.quantity === 0) {
            const recovered = recoverNumericFromRawData(record.raw_data, 'quantity', ['qtd', 'quantidade']);
            if (recovered !== null) record.quantity = recovered;
          }
          if (record.total_value == null || record.total_value === 0) {
            const recovered = recoverNumericFromRawData(record.raw_data, 'total_value', ['valor_total', 'totalvalue']);
            if (recovered !== null) record.total_value = recovered;
          }
        }
      });

      // Safety check: verificar se h√° campos inesperados (n√£o deveria acontecer ap√≥s allowedFields)
      if (process.env.NODE_ENV === 'development' && cleanedRecords.length > 0) {
        const sample = cleanedRecords[0];
        const expectedFields = ['company_group_id', 'external_id', 'raw_data', ...Array.from(allowed)];
        const unexpected = Object.keys(sample).filter(k => !expectedFields.includes(k));
        if (unexpected.length > 0) {
          console.warn(`‚ö†Ô∏è Campos inesperados em ${config.entity_type}: ${unexpected.join(', ')}`);
        }
      }

      // Chave de conflito deve corresponder ao UNIQUE constraint de cada tabela
      const conflictKeyMap: Record<string, string> = {
        external_companies: 'company_group_id,external_id',
        external_employees: 'company_group_id,external_id',
        external_products: 'company_group_id,external_id',
        external_sales: 'company_group_id,external_id',
        external_cash_flow: 'company_group_id,external_id',
        external_cash_flow_statement: 'company_group_id,external_id',
        external_categories: 'company_group_id,external_id',
        external_stock: 'company_group_id,external_id',
      };
      const conflictKey = conflictKeyMap[tableName] || 'company_group_id,external_id';

      console.log(`üíæ Salvando ${cleanedRecords.length} registros em ${tableName} (conflict: ${conflictKey})...`);

      const batchSize = 200;
      let savedCount = 0;
      let failedBatches = 0;
      const totalBatches = Math.ceil(cleanedRecords.length / batchSize);

      for (let i = 0; i < cleanedRecords.length; i += batchSize) {
        const batch = cleanedRecords.slice(i, i + batchSize);
        const batchNumber = Math.floor(i / batchSize) + 1;

        let success = false;
        for (let attempt = 1; attempt <= 3; attempt++) {
          try {
            const { error: upsertError } = await supabaseAdmin
              .from(tableName)
              .upsert(batch, { onConflict: conflictKey, ignoreDuplicates: false });

            if (!upsertError) {
              savedCount += batch.length;
              success = true;
              break;
            }

            // Se √© erro de schema/constraint, n√£o adianta retry
            if (upsertError.message.includes('column') ||
                upsertError.message.includes('violates') ||
                upsertError.message.includes('schema')) {
              console.error(`‚ùå Erro de schema no lote ${batchNumber}:`, upsertError.message);
              if (batch.length > 0) {
                console.error(`‚ùå Exemplo de registro:`, JSON.stringify(batch[0], null, 2).substring(0, 500));
              }
              break; // N√£o retry em erros de schema
            }

            if (attempt < 3) {
              console.warn(`‚ö†Ô∏è Lote ${batchNumber}: tentativa ${attempt} falhou, retry em 2s...`);
              await new Promise(resolve => setTimeout(resolve, 2000));
            } else {
              console.error(`‚ùå Lote ${batchNumber} falhou ap√≥s 3 tentativas: ${upsertError.message}`);
            }
          } catch (error: any) {
            if (attempt >= 3) {
              console.error(`‚ùå Exce√ß√£o no lote ${batchNumber}: ${error.message}`);
            } else {
              await new Promise(resolve => setTimeout(resolve, 2000));
            }
          }
        }

        if (!success) {
          failedBatches++;
          // CONTINUAR para pr√≥ximo batch em vez de falhar tudo
          console.warn(`‚ö†Ô∏è Lote ${batchNumber}/${totalBatches} falhou, continuando com pr√≥ximos lotes...`);
        }

        // Log de progresso a cada 5 batches
        if (batchNumber % 5 === 0 || batchNumber === totalBatches) {
          console.log(`üìä Progresso: ${batchNumber}/${totalBatches} lotes (${savedCount} salvos, ${failedBatches} falharam)`);
        }
      }

      // Se TODOS os batches falharam, a√≠ sim √© erro
      if (savedCount === 0 && cleanedRecords.length > 0) {
        throw new Error(`Nenhum registro salvo. Todos os ${totalBatches} lotes falharam.`);
      }

      // Se alguns batches falharam, logar warning mas n√£o falhar
      if (failedBatches > 0) {
        console.warn(`‚ö†Ô∏è ${failedBatches}/${totalBatches} lotes falharam. ${savedCount}/${cleanedRecords.length} registros salvos.`);
      }

      console.log(`‚úÖ Salvamento: ${savedCount}/${cleanedRecords.length} registros em ${tableName}`);
    }

    // ----------------------------------------------------------
    // 8. Atualizar progresso
    // ----------------------------------------------------------
    if (hasDateField) {
      const newProcessedDays = processedDays + daysInBatch;
      const newProcessedRecords = (queueItem.processed_records || 0) + rows.length;
      const newProgress = Math.min(Math.round((newProcessedDays / queueItem.total_days) * 100), 100);
      const hasMore = newProcessedDays < queueItem.total_days;

      console.log(`üìä Atualizando progresso: ${processedDays} ‚Üí ${newProcessedDays}/${queueItem.total_days} dias`);

      // CR√çTICO: salvar progresso no banco ‚Äî sem isso, o loop repete o mesmo dia infinitamente
      const { error: updateError } = await supabaseAdmin
        .from('sync_queue')
        .update({
          processed_days: newProcessedDays,
          processed_records: newProcessedRecords,
          progress: newProgress,
          status: hasMore ? 'processing' : 'completed',
          updated_at: new Date().toISOString(),
          ...(hasMore ? {} : { finished_at: new Date().toISOString() }),
        })
        .eq('id', queueItem.id);

      if (updateError) {
        console.error('‚ùå ERRO CR√çTICO ao atualizar progresso no banco:', updateError);
        return NextResponse.json({
          status: 'day_error',
          queue_id: queueItem.id,
          error: `Falha ao salvar progresso: ${updateError.message}. Loop interrompido para evitar duplica√ß√£o.`,
        }, { status: 500 });
      }

      // Verificar se o update realmente persistiu
      const { data: verification } = await supabaseAdmin
        .from('sync_queue')
        .select('processed_days')
        .eq('id', queueItem.id)
        .single();

      if (!verification || verification.processed_days !== newProcessedDays) {
        console.error(`‚ùå VERIFICA√á√ÉO FALHOU: esperado processed_days=${newProcessedDays}, encontrado=${verification?.processed_days}`);
        return NextResponse.json({
          status: 'day_error',
          queue_id: queueItem.id,
          error: `Progresso n√£o persistiu no banco. Esperado: ${newProcessedDays}, Atual: ${verification?.processed_days}. Loop interrompido.`,
        }, { status: 500 });
      }

      console.log(`‚úÖ Progresso verificado: ${newProcessedDays}/${queueItem.total_days} dias, ${newProcessedRecords} registros`);

      // Se n√£o h√° mais dias E o update acima n√£o marcou completed, finalizar via RPC
      if (!hasMore) {
        console.log('‚úÖ Todos os dias processados. Finalizando item da fila...');
        await supabaseAdmin.rpc('finish_sync_queue_item', {
          p_queue_id: queueItem.id,
          p_status: 'completed',
          p_total_records: newProcessedRecords,
          p_error_message: null,
        });
      }

      return NextResponse.json({
        status: hasMore ? 'processing' : 'completed',
        queue_id: queueItem.id,
        day: `${batchStartDateStr} at√© ${batchEndDateStr}`,
        day_records: rows.length,
        processed_days: newProcessedDays,
        total_days: queueItem.total_days,
        processed_records: newProcessedRecords,
        has_more: hasMore,
        progress: newProgress,
      });
    } else {
      // Entidades sem campo de data: processar tudo de uma vez e finalizar
      // NOTA: Para entidades sem data (companies, employees, products, categories, stock),
      // processamos tudo de uma vez, mas com prote√ß√£o TOPN(5000) j√° adicionada acima
      // para evitar timeout ao buscar todos os registros de uma vez
      
      const newProcessedDays = queueItem.total_days; // Marcar todos os dias como processados
      const newProcessedRecords = rows.length;

      console.log(`üìä Processando entidade sem data (${config.entity_type}): ${rows.length} registros`);

      // Finalizar item imediatamente
      await supabaseAdmin.rpc('finish_sync_queue_item', {
        p_queue_id: queueItem.id,
        p_status: 'completed',
        p_total_records: newProcessedRecords,
        p_error_message: null,
      });

      return NextResponse.json({
        status: 'completed',
        queue_id: queueItem.id,
        day_records: rows.length,
        processed_days: newProcessedDays,
        total_days: queueItem.total_days,
        processed_records: newProcessedRecords,
        has_more: false,
        progress: 100,
      });
    }

  } catch (error: any) {
    console.error('‚ùå Erro ao processar dia:', error);
    console.error('‚ùå Stack trace:', error.stack);
    
    // Tentar atualizar o status do item da fila se tivermos o ID
    if (queueIdForError) {
      try {
        await supabaseAdmin.rpc('finish_sync_queue_item', {
          p_queue_id: queueIdForError,
          p_status: 'failed',
          p_total_records: 0,
          p_error_message: error.message || 'Erro desconhecido ao processar',
        });
      } catch (updateError) {
        console.error('‚ùå Erro ao atualizar status da fila:', updateError);
      }
    }
    
    return NextResponse.json({
      status: 'day_error',
      queue_id: queueIdForError || '',
      error: error.message || 'Erro ao processar dia',
    }, { status: 500 });
  }
}

// ============================================================
// HELPERS - Fun√ß√µes de transforma√ß√£o
// ============================================================

/** Encontra valor de um campo no row do Power BI, testando v√°rias varia√ß√µes de nome */
function findFieldValue(row: any, fieldName: string): any {
  // 1. Nome exato
  if (row[fieldName] !== undefined) return row[fieldName];

  // 2. Com colchetes: [fieldName]
  if (fieldName.startsWith('[') && fieldName.endsWith(']')) {
    const clean = fieldName.slice(1, -1);
    if (row[clean] !== undefined) return row[clean];
    if (row[fieldName] !== undefined) return row[fieldName];
    return undefined;
  }

  // 3. Procurar varia√ß√µes nas chaves do row
  const keys = Object.keys(row);
  const match = keys.find(k =>
    k === fieldName ||
    k === `[${fieldName}]` ||
    k.endsWith(`[${fieldName}]`) ||
    k.toLowerCase() === fieldName.toLowerCase() ||
    k.toLowerCase() === `[${fieldName.toLowerCase()}]` ||
    k.toLowerCase().endsWith(`[${fieldName.toLowerCase()}]`)
  );

  return match ? row[match] : undefined;
}

/** Converte valor para n√∫mero, retornando fallback se imposs√≠vel */
function toNumber(value: any, fallback: number | null = null): number | null {
  if (value === null || value === undefined) return fallback;
  const num = parseFloat(value);
  return isNaN(num) ? fallback : num;
}

/** Converte valor para data ISO (YYYY-MM-DD) */
function toDateISO(value: any): string | null {
  if (!value) return null;
  try {
    const date = new Date(value);
    return isNaN(date.getTime()) ? null : date.toISOString().split('T')[0];
  } catch {
    return null;
  }
}

/** Busca campo no raw_data por nome parcial */
function findInRawData(rawData: any, ...searchTerms: string[]): any {
  if (!rawData) return undefined;
  const keys = Object.keys(rawData);
  for (const term of searchTerms) {
    // Prioridade 1: match exato com colchetes
    const exact = keys.find(k => k === `[${term}]` || k === term);
    if (exact) return rawData[exact];
    // Prioridade 2: match parcial case-insensitive
    const partial = keys.find(k => k.toLowerCase().includes(term.toLowerCase()));
    if (partial) return rawData[partial];
  }
  return undefined;
}

/**
 * Tenta recuperar um valor num√©rico do raw_data usando fuzzy matching de chaves
 */
function recoverNumericFromRawData(rawData: any, fieldName: string, aliases: string[]): number | null {
  if (!rawData) return null;
  
  const keys = Object.keys(rawData);
  
  // 1. Tentar match exato
  for (const alias of [fieldName, `[${fieldName}]`, ...aliases]) {
    if (rawData[alias] !== undefined && rawData[alias] !== null) {
      const num = parseFloat(rawData[alias]);
      if (!isNaN(num)) return num;
    }
  }
  
  // 2. Tentar match parcial (case-insensitive)
  for (const alias of [fieldName, ...aliases]) {
    const match = keys.find(k => k.toLowerCase().includes(alias.toLowerCase()));
    if (match && rawData[match] !== undefined && rawData[match] !== null) {
      const num = parseFloat(rawData[match]);
      if (!isNaN(num)) return num;
    }
  }
  
  return null;
}

// Campos num√©ricos por entidade
const NUMERIC_FIELDS = ['amount', 'quantity', 'total_value', 'cost'];
// Campos de data por entidade
const DATE_FIELDS = ['sale_date', 'transaction_date', 'date', 'updated_at_external'];
// Campos obrigat√≥rios com fallback 0
const REQUIRED_NUMERIC: Record<string, string[]> = {
  sales: ['quantity', 'total_value'],
  cash_flow: ['amount'],
  cash_flow_statement: ['amount'],
};

function transformRecord(row: any, config: any, companyGroupId: string): any {
  const fieldMappings = config.field_mapping || config.field_mappings || {};
  const record: any = {
    company_group_id: companyGroupId,
    raw_data: row,
  };

  // field_mapping √© SEMPRE { pbiField: localField }
  // (garantido pelo frontend ap√≥s Cmd 8 do Batch 1)
  Object.entries(fieldMappings).forEach(([pbiField, localField]) => {
    if (!localField || typeof localField !== 'string') return;
    
    let value = null;
    
    // Tentar encontrar o valor no row com diferentes formatos de nome PBI
    // 1. Nome exato
    if (row[pbiField] !== undefined) {
      value = row[pbiField];
    }
    // 2. Com colchetes: [NomeCampo] ou Table[NomeCampo]
    else {
      const cleanPbi = pbiField.replace(/^\[|\]$/g, '');
      const keys = Object.keys(row);
      const matchingKey = keys.find(k => 
        k === pbiField ||
        k === `[${cleanPbi}]` ||
        k === cleanPbi ||
        k.endsWith(`[${cleanPbi}]`)
      );
      if (matchingKey) {
        value = row[matchingKey];
      }
    }
    
    // Converter datas para YYYY-MM-DD
    if (value != null && (localField.includes('date') || localField.includes('Date'))) {
      try {
        const date = new Date(value);
        if (!isNaN(date.getTime())) {
          value = date.toISOString().split('T')[0];
        }
      } catch (e) {
        // Manter valor original se n√£o conseguir converter
      }
    }
    
    // Converter campos num√©ricos
    if (['amount', 'quantity', 'total_value', 'cost', 'min_quantity', 'max_quantity', 
         'last_cost', 'average_cost', 'conversion_factor'].includes(localField)) {
      if (value != null) {
        const numValue = parseFloat(value);
        value = isNaN(numValue) ? 0 : numValue;
      } else if (['quantity', 'total_value'].includes(localField) && config.entity_type === 'sales') {
        value = 0; // Campos obrigat√≥rios de vendas
      }
    }
    
    // Adicionar ao registro
    if (value != null) {
      record[localField] = value;
    }
  });

  // Recovery: tentar encontrar campos obrigat√≥rios no raw_data se n√£o foram mapeados
  if (config.entity_type === 'cash_flow' && record.amount == null) {
    const recovered = recoverNumericFromRawData(record.raw_data, 'amount', ['valor', 'value']);
    if (recovered !== null) record.amount = recovered;
  }
  
  if (config.entity_type === 'sales') {
    if (record.quantity == null || record.quantity === 0) {
      const recovered = recoverNumericFromRawData(record.raw_data, 'quantity', ['qtd', 'quantidade']);
      if (recovered !== null) record.quantity = recovered;
    }
    if (record.total_value == null || record.total_value === 0) {
      const recovered = recoverNumericFromRawData(record.raw_data, 'total_value', ['valor_total', 'totalvalue']);
      if (recovered !== null) record.total_value = recovered;
    }
  }

  // Verificar campos n√£o mapeados do Power BI (log apenas 1% para n√£o spammar)
  if (Math.random() < 0.01) {
    const unmappedRecordKeys = Object.keys(row).filter(k => {
      return !Object.keys(fieldMappings).some(pbi =>
        k === pbi ||
        k === `[${pbi}]` ||
        k.endsWith(`[${pbi}]`) ||
        k.toLowerCase() === pbi.toLowerCase()
      );
    });
    
    if (unmappedRecordKeys.length > 0) {
      console.log('‚ö†Ô∏è Campos n√£o mapeados do Power BI:', unmappedRecordKeys);
    }
  }

  return record;
}